{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import numpy as np\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"pb\"\n",
    "model = tf.saved_model.load(model_path)\n",
    "movenet = model.signatures['serving_default']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret, frame = cap.read()\n",
    "frame_height, frame_width, _ = frame.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEFT_ELBOW_IDX = 7\n",
    "RIGHT_ELBOW_IDX = 8\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('punch_coordinates2.txt', 'w') as f:\n",
    "\n",
    "    # Read the video file.\n",
    "    cap = cv2.VideoCapture('video1.mp4')\n",
    "\n",
    "    while True:\n",
    "        # Read a frame from the video.\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        if not ret:\n",
    "            # End of video.\n",
    "            break\n",
    "\n",
    "        # Get the frame width and height.\n",
    "        frame_height, frame_width, _ = frame.shape\n",
    "\n",
    "        # Resize and pad the image to fit the expected input shape.\n",
    "        image = tf.expand_dims(frame, axis=0)\n",
    "        image = tf.cast(tf.image.resize_with_pad(\n",
    "            image, 192, 192), dtype=tf.int32)\n",
    "\n",
    "        # Run model inference.\n",
    "        outputs = movenet(image)\n",
    "\n",
    "        # Get the keypoint coordinates and confidence scores.\n",
    "        keypoints = np.squeeze(outputs['output_0'])\n",
    "\n",
    "        # Get the coordinates of the left and right elbows.\n",
    "        left_elbow_coords = None\n",
    "        right_elbow_coords = None\n",
    "\n",
    "        if keypoints.ndim == 2:\n",
    "            # If only one person is detected in the frame.\n",
    "            if LEFT_ELBOW_IDX < keypoints.shape[0]:\n",
    "                left_elbow_coords = (int(keypoints[LEFT_ELBOW_IDX][1] * frame_width), int(\n",
    "                    keypoints[LEFT_ELBOW_IDX][0] * frame_height))\n",
    "            if RIGHT_ELBOW_IDX < keypoints.shape[0]:\n",
    "                right_elbow_coords = (int(keypoints[RIGHT_ELBOW_IDX][1] * frame_width), int(\n",
    "                    keypoints[RIGHT_ELBOW_IDX][0] * frame_height))\n",
    "\n",
    "        elif keypoints.ndim == 3:\n",
    "            # If multiple people are detected in the frame, use the person with the highest confidence score.\n",
    "            max_score_idx = np.argmax(keypoints[:, :, 2])\n",
    "            if LEFT_ELBOW_IDX < keypoints.shape[1]:\n",
    "                left_elbow_coords = (int(\n",
    "                    keypoints[max_score_idx, LEFT_ELBOW_IDX][1] * frame_width), int(keypoints[max_score_idx, LEFT_ELBOW_IDX][0] * frame_height))\n",
    "            if RIGHT_ELBOW_IDX < keypoints.shape[1]:\n",
    "                right_elbow_coords = (int(\n",
    "                    keypoints[max_score_idx, RIGHT_ELBOW_IDX][1] * frame_width), int(keypoints[max_score_idx, RIGHT_ELBOW_IDX][0] * frame_height))\n",
    "\n",
    "        # Save the coordinates of both elbows in the file.\n",
    "        if left_elbow_coords is not None and right_elbow_coords is not None:\n",
    "            f.write(f\"{left_elbow_coords},{right_elbow_coords}\\n\")\n",
    "\n",
    "    # Release the video capture object.\n",
    "    cap.release()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
